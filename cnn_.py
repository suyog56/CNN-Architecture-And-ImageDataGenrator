# -*- coding: utf-8 -*-
"""CNN .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OvRvPQJmyg_SZcg2sL0rRqiDOwk--sLx
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download bhavikjikadara/dog-and-cat-classification-dataset

import zipfile
zip_ref = zipfile.ZipFile("/content/dog-and-cat-classification-dataset.zip","r")
zip_ref.extractall("/content")
zip_ref.close()

import tensorflow as tensorflow
from tensorflow import keras
from keras import Sequential
from keras .layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization

import os
import glob

# Define the source directory containing the Cat and Dog folders
source_dir = '/content/PetImages'

# Get the list of all image file paths for cats and dogs using glob
cat_image_paths = glob.glob(os.path.join(source_dir, 'Cat', '*'))
dog_image_paths = glob.glob(os.path.join(source_dir, 'Dog', '*'))

print(f"Found {len(cat_image_paths)} cat images and {len(dog_image_paths)} dog images.")

from sklearn.model_selection import train_test_split

# Combine cat and dog image paths and create corresponding labels (0 for cats, 1 for dogs)
all_image_paths = cat_image_paths + dog_image_paths
labels = [0] * len(cat_image_paths) + [1] * len(dog_image_paths)

# Split the data into training and testing sets (80% train, 20% test)
train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(
    all_image_paths, labels, test_size=0.2, random_state=42, stratify=labels
)

print(f"Training set: {len(train_image_paths)} images")
print(f"Testing set: {len(test_image_paths)} images")



from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd

# Create DataFrames from image paths and labels
train_df = pd.DataFrame({'filename': train_image_paths, 'class': train_labels})
test_df = pd.DataFrame({'filename': test_image_paths, 'class': test_labels})

# Convert labels to string type for flow_from_dataframe
train_df['class'] = train_df['class'].astype(str)
test_df['class'] = test_df['class'].astype(str)

# Create data generators for training and testing
train_datagen = ImageDataGenerator(rescale=1./255) # Rescale pixel values to be between 0 and 1
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    train_df,
    x_col='filename',
    y_col='class',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

validation_generator = test_datagen.flow_from_dataframe(
    test_df,
    x_col='filename',
    y_col='class',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)



"""#genratoros

train_ds = keras.utils.image_dataset_from_directory(
    directory="/content/PetImages",
    labels="inferred",
    label_mode="int",
    batch_size=32,
    image_size=(256,256)
)


Validation_ds = keras.utils.image_dataset_from_directory(
    directory="/content/PetImages",
    labels="inferred",
    label_mode="int",
    batch_size=32,
    image_size=(256,256)
)
#Normlaize
def process(image,label):
   image = tf.cast(image/255,tf.float32)
   return image,label

   train_ds train_ds.map(process)
   validation_ds = validation_ds.map(process)
"""

#create cnn mmodel
model = Sequential()

model.add(Conv2D(32,kernel_size = (3,3),padding ="valid",activation = "relu",input_shape = (256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 2 ,padding = "valid"))

model.add(Conv2D(64,kernel_size = (3,3),padding ="valid",activation = "relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 2 ,padding = "valid"))

model.add(Conv2D(64,kernel_size = (3,3),padding ="valid",activation = "relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 3 ,padding = "valid"))

model.add(Flatten())
model.add(Dense(128,activation = "relu"))
model.add(Dropout(0.1))
model.add(Dense(64,activation = "relu"))
model.add(Dense(1,activation = "sigmoid"))

model.summary()

model.compile(optimizer="adam",loss = "binary_crossentropy",metrics = ["accuracy"])

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history = model.fit(
    train_generator,#train_augmented_generator,
    epochs=2,
    validation_data=validation_generator,
    callbacks=[early_stopping]
)

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 8))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], color='red', label='Train')
plt.plot(history.history['val_accuracy'], color='blue', label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], color='red', label='Train')
plt.plot(history.history['val_loss'], color='blue', label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

import cv2

import random
# Select a random image path from the test set
random_test_image_path = random.choice(test_image_paths)
test_img = cv2.imread(random_test_image_path)

# Check if the image was loaded successfully
if test_img is None:
    print(f"Error: Could not load image from {random_test_image_path}")
else:
    print(f"Loaded image from: {random_test_image_path}")

test_img.shape

plt.imshow(test_img)

# Preprocess the image
test_img_resized = cv2.resize(test_img,(256,256))
test_input = test_img_resized.reshape((1,256,256,3))

# Make a prediction
prediction = model.predict(test_input)

# Print the prediction
if prediction[0][0] > 0.5:
    print("The image is predicted to be a Dog.")
else:
    print("The image is predicted to be a Cat.")



import random
# Select a random image path from the test set
random_test_image_path = random.choice(test_image_paths)
test_img = cv2.imread(random_test_image_path)

# Check if the image was loaded successfully
if test_img is None:
    print(f"Error: Could not load image from {random_test_image_path}")
else:
    print(f"Loaded image from: {random_test_image_path}")

plt.imshow(test_img)

# Preprocess the image
test_img_resized = cv2.resize(test_img,(256,256))
test_input = test_img_resized.reshape((1,256,256,3))

# Make a prediction
prediction = model.predict(test_input)

# Print the prediction
if prediction[0][0] > 0.5:
    print("The image is predicted to be a Dog.")
else:
    print("The image is predicted to be a Cat.")

"""Data Augmentation"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array,array_to_img

source_dir = '/content/Data Augmentation/Ai1.jpg'

img = image.load_img(source_dir,target_size=(200,200))
import matplotlib.pyplot as plt
plt.imshow(img)

img,type(img)

data_gen = ImageDataGenerator(
    rotation_range=40,zoom_range = 0.2,height_shift_range=0.2,
    width_shift_range=0.2,vertical_flip=True,horizontal_flip=True,#fill_mode,reflect
    fill_mode='nearest'
)

img = img_to_array(img)
img.shape

input_batch = img.reshape(1,200,200,3)

import os

# Create the directory if it doesn't exist
if not os.path.exists("/content/aug"):
    os.makedirs("/content/aug")

i = 0
for ouput in data_gen.flow(input_batch,batch_size = 1,save_to_dir="/content/aug"):
  #flow_from_directory when class is divided into folder
  i =i+1
  if i ==10:
    break

input_batch.shape

import os
import matplotlib.pyplot as plt

#the directory if it doesn't exist
if not os.path.exists("/content/aug"):
    os.makedirs("/content/aug")

# an ImageDataGenerator with augmentation parameters
data_gen = ImageDataGenerator(
    rotation_range=40,
    zoom_range=0.2,
    height_shift_range=0.2,
    width_shift_range=0.2,
    vertical_flip=True,
    horizontal_flip=True,
    fill_mode='nearest'
)


# Use the flow method to generate augmented images and save them
count = 0
for batch in data_gen.flow(input_batch, batch_size=1, save_to_dir="/content/aug", save_prefix="aug_image", save_format="png"):
    count += 1
    if count > 500: # Generate and save 500 augmented images as an example
        break

print(f"Generated and saved {count} augmented images to /content/aug")





"""# Create an ImageDataGenerator with data augmentation
datagen = ImageDataGenerator(
    rescale=1./255,          
    rotation_range=20,      
    width_shift_range=0.2,   # Shift images horizontally by a random fraction
    height_shift_range=0.2,  # Shift images vertically by a random fraction
    shear_range=0.2,         # Apply shearing transformations
    zoom_range=0.2,          # Apply random zoom
    horizontal_flip=True,    # Flip images horizontally
    fill_mode='nearest'      # Fill in new pixels created by transformations
)

# Define the directory containing your image data
data_dir = '/content/Data Augmentation' # Assuming your images are in this directory

# Use flow_from_directory to generate batches of augmented images
augmented_data_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(256, 256),  # Resize images to match your model input size
    batch_size=32,
    class_mode='binary'      # Or 'categorical' depending on your task
)

# You can now use 'augmented_data_generator' to train your model
# model.fit(augmented_data_generator, ...)
"""

